{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d9952a6-6443-4e29-8ada-2a6078a2601c",
   "metadata": {},
   "source": [
    "# Description of my Wrangling Effort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e480b3-458d-4e86-91ce-4d993d3a3b48",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dc65b3-9bee-4cfb-a416-6e79e76fe75a",
   "metadata": {},
   "source": [
    "This project addresses the tidiness and data quality issues with the tweet data of a Twitter user, @dog_rates, of over 5000+ tweet. @dog_rates is a tweeter user with over 4 million followers and with international media coverage. @dog_rates rates people's dogs with a humorous comment about their dog.\n",
    "\n",
    "These data are from different sources and dirty, hence, there is need to wrangle them to create interesting and trustworthy analyses and visualizations.\n",
    "\n",
    "All wrangling efforts were documented in a Jupyter Notebook, and showcased through analyses and visualizations using Python (and its libraries)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7463cff-8c51-4cfa-ab73-0c75cf45583e",
   "metadata": {},
   "source": [
    "## Data Source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc5adda-a518-4665-bd76-9aff86fc1c23",
   "metadata": {},
   "source": [
    "In order to achieve my goal of wrangling the 3 dataset provided from different sources and in different format, I researched the company and related my findings to the data provided. The sources of this data are:\n",
    "\n",
    "- csv: The title of this file is twitter_archive_enhanced which was downloaded from the Udacity website and uploaded to the jupyter notebook. The file was read and the columns and rows were inspected. The WeRateDogs Twitter archive contains basic tweet data for all 5000+ of their tweets, but not everything. I extracted this data programmatically. The ratings probably aren't all correct. Same goes for the dog names and probably dog stages.\n",
    "\n",
    "- tsv: The title of the tsv file is image_predictions which is expected to downloaded as a .tsv file. This data is from the resulting data gathered from classification of breeds of dogs via neural network on every image in the WeRateDogs Twitter archive. This table contains full of image predictions (the top three only) alongside each tweet ID, image URL, and the image number that corresponded to the most confident prediction (numbered 1 to 4 since tweets can have up to four images).\n",
    "\n",
    "- Twitter API: This contains the omitted data - retweet count and favorite count are two of the notable column omissions. Fortunately, this additional data can be gathered by anyone from Twitter's API. Well, \"anyone\" who has access to data for the 3000 most recent tweets, at least. Here, I used the WeRateDogs Twitter archive and specifically the tweet IDs within it to gather this data for all 5000+ by querying Twitter's API to gather this valuable data. A developer was rquired for this to be achieved but the data was also provided by Udacity. Due the challenges of getting twitter's approval so I can finish my project on time. I downloaded the data as a json file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13017ec2-f671-4d3c-ae7d-659c5159e56b",
   "metadata": {},
   "source": [
    "## Data Wrangling Effort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5653465-07a7-4860-b029-d7de3ac0e0b6",
   "metadata": {},
   "source": [
    "Data wrangling is a superset of data mining and requires processes that some data mining uses, but not always. The process of data mining is to find patterns within large data sets, where data wrangling transforms data in order to deliver insights about that data (Wikipedia).\n",
    "\n",
    "Some of the effort taking was:\n",
    "\n",
    "- downloading the data\n",
    "- importing the data into jupyter notebook. For those with url, I used requests library to get the data and stored the data in the requested format\n",
    "- import the various libraries\n",
    "- read the data adopting different which is a function of the data format\n",
    "- look out for patterns visually and programmatically to spot data inaccuracy\n",
    "- clean the data by removing unwanted columns and renaming column headers that are not well described.\n",
    "- after cleaning the data, I merged the 3 tables together and saved it as a csv file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f039d8c-9074-44fd-b7bb-b26480820f95",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9106b8e-fa28-4c09-b4ce-be6982fb9827",
   "metadata": {},
   "source": [
    "The libraries used are:\n",
    "    \n",
    "- pandas\n",
    "- numpy\n",
    "- requests\n",
    "- tweepy\n",
    "- json\n",
    "- matplotlib.pyplot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
